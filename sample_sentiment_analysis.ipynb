{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install textblob\n",
    "# !pip install mlxtend\n",
    "# !pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180d4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import preprocess_kgptalkie as ps\n",
    "# nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b44e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data = pd.read_csv(os.listdir()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d82bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff02fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  count\n",
       "0  positive  25000\n",
       "1  negative  25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the balance of the sentiment column\n",
    "data['sentiment'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99db86",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3a1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stop_words(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens =[token for token in tokens if token.lower() not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3ca559",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf53562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewers mentioned watching 1 Oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production . &lt; br / &gt; &lt; br / ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically 's family little boy ( Jake ) thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei 's `` Love Time Money '' visuall...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job . n't creative or...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot , bad dialogue , bad acting , idiotic...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>'m going disagree previous comment side Maltin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects Star Trek movies high art , fans e...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One reviewers mentioned watching 1 Oz episode ...  positive\n",
       "1      wonderful little production . < br / > < br / ...  positive\n",
       "2      thought wonderful way spend time hot summer we...  positive\n",
       "3      Basically 's family little boy ( Jake ) thinks...  negative\n",
       "4      Petter Mattei 's `` Love Time Money '' visuall...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movie right good job . n't creative or...  positive\n",
       "49996  Bad plot , bad dialogue , bad acting , idiotic...  negative\n",
       "49997  Catholic taught parochial elementary schools n...  negative\n",
       "49998  'm going disagree previous comment side Maltin...  negative\n",
       "49999  one expects Star Trek movies high art , fans e...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cd0b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2eea58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewers mentioned watching 1 Oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production . &lt; br / &gt; &lt; br / ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically 's family little boy ( Jake ) thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei 's `` Love Time Money `` visuall...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job . n't creative or...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot , bad dialogue , bad acting , idiotic...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Catholic taught parochial elementary schools n...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>'m going disagree previous comment side Maltin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects Star Trek movies high art , fans e...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One reviewers mentioned watching 1 Oz episode ...  positive\n",
       "1      wonderful little production . < br / > < br / ...  positive\n",
       "2      thought wonderful way spend time hot summer we...  positive\n",
       "3      Basically 's family little boy ( Jake ) thinks...  negative\n",
       "4      Petter Mattei 's `` Love Time Money `` visuall...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movie right good job . n't creative or...  positive\n",
       "49996  Bad plot , bad dialogue , bad acting , idiotic...  negative\n",
       "49997  Catholic taught parochial elementary schools n...  negative\n",
       "49998  'm going disagree previous comment side Maltin...  negative\n",
       "49999  one expects Star Trek movies high art , fans e...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b815de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize_text(text):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c72ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ce4d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mentioned watching 1 Oz episode '...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production . &lt; br / &gt; &lt; br / ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically 's family little boy ( Jake ) think ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei 's `` Love Time Money `` visuall...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job . n't creative or...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot , bad dialogue , bad acting , idiotic...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Catholic taught parochial elementary school nu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>'m going disagree previous comment side Maltin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects Star Trek movie high art , fan exp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One reviewer mentioned watching 1 Oz episode '...  positive\n",
       "1      wonderful little production . < br / > < br / ...  positive\n",
       "2      thought wonderful way spend time hot summer we...  positive\n",
       "3      Basically 's family little boy ( Jake ) think ...  negative\n",
       "4      Petter Mattei 's `` Love Time Money `` visuall...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movie right good job . n't creative or...  positive\n",
       "49996  Bad plot , bad dialogue , bad acting , idiotic...  negative\n",
       "49997  Catholic taught parochial elementary school nu...  negative\n",
       "49998  'm going disagree previous comment side Maltin...  negative\n",
       "49999  one expects Star Trek movie high art , fan exp...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb76738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text2(text):\n",
    "    import re\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]','', text) # remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove extra whit spaces\n",
    "    text = re.sub(r'<[^>]+>', '', text) # remove html tags\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d81ca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mentioned watching 1 Oz episode l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically s family little boy Jake think s zom...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei s Love Time Money visually stunn...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job nt creative origi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Catholic taught parochial elementary school nu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>m going disagree previous comment side Maltin ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects Star Trek movie high art fan expec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One reviewer mentioned watching 1 Oz episode l...  positive\n",
       "1      wonderful little production br br filming tech...  positive\n",
       "2      thought wonderful way spend time hot summer we...  positive\n",
       "3      Basically s family little boy Jake think s zom...  negative\n",
       "4      Petter Mattei s Love Time Money visually stunn...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movie right good job nt creative origi...  positive\n",
       "49996  Bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  Catholic taught parochial elementary school nu...  negative\n",
       "49998  m going disagree previous comment side Maltin ...  negative\n",
       "49999  one expects Star Trek movie high art fan expec...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review']= data['review'].apply(lambda x: clean_text2(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ae1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie try hard something s good movie want fooled begining end failsFrom start get interesting fall apart re hoping ending give clue going nt br br  -> negative\n"
     ]
    }
   ],
   "source": [
    "print(f\"{data['review'][9000]} -> {data['sentiment'][9000]}\") # this pass mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7a47a",
   "metadata": {},
   "source": [
    "## Training dataset and evaluate\n",
    "#### Using Pipeline to containarize two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d2101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241cdd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;nb_classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;nb_classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('nb_classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Container for TfidfVectorizer and the MultinomialNB\n",
    "clf = Pipeline([('tfidf', TfidfVectorizer()), ('nb_classifier', MultinomialNB())])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a768f254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;nb_classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;nb_classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('nb_classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('nb_classifier', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9516f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87      6157\n",
      "    positive       0.89      0.85      0.87      6343\n",
      "\n",
      "    accuracy                           0.87     12500\n",
      "   macro avg       0.87      0.87      0.87     12500\n",
      "weighted avg       0.87      0.87      0.87     12500\n",
      "\n",
      "0.86984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Evaluate the performance of the model using classification, confussion matrix and accuracy score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b236a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.76664\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.84      0.78      6157\n",
      "    positive       0.82      0.69      0.75      6343\n",
      "\n",
      "    accuracy                           0.77     12500\n",
      "   macro avg       0.77      0.77      0.77     12500\n",
      "weighted avg       0.77      0.77      0.77     12500\n",
      "\n",
      "Confussion Matrix: [[5188  969]\n",
      " [1948 4395]]\n",
      "Accuracy Score: 0.76664\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.84      0.78      6157\n",
      "    positive       0.82      0.69      0.75      6343\n",
      "\n",
      "    accuracy                           0.77     12500\n",
      "   macro avg       0.77      0.77      0.77     12500\n",
      "weighted avg       0.77      0.77      0.77     12500\n",
      "\n",
      "Confussion Matrix: [[5188  969]\n",
      " [1948 4395]]\n",
      "['negative' 'positive' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create an object of the class and train the model\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf_clf = Pipeline([('tfidf', TfidfVectorizer()), ('rf_classifier', rf_clf)])\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model using classification, confussion matrix and accuracy score\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b2725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8988\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90      6157\n",
      "    positive       0.89      0.91      0.90      6343\n",
      "\n",
      "    accuracy                           0.90     12500\n",
      "   macro avg       0.90      0.90      0.90     12500\n",
      "weighted avg       0.90      0.90      0.90     12500\n",
      "\n",
      "Confussion Matrix: [[5456  701]\n",
      " [ 564 5779]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HolarTech\\anacon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create an object of the class and train the model\n",
    "log_reg = Pipeline([('tfidf', TfidfVectorizer()), ('model', LogisticRegression(random_state=42))])\n",
    "log_reg.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Evaluate the performance of the model using classification, confussion matrix and accuracy score\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "# Save the model\n",
    "dump(log_reg, 'logistic_reg.pkl')\n",
    "\n",
    "\n",
    "# Hyperparameter tuning to adjust the model parameters in order to improve its performance\n",
    "# Using GridSearchCV class of sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 0.5, 1, 2, 3, 5, 10], # regularization strength\n",
    "    'model__penalty': [None, 'l2'], # regularization type\n",
    "    'model__max_iter': [1000, 5000, 10000]\n",
    "    }\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train.values, y_train.values)\n",
    "\n",
    "# get the best model with optimized hyperparameters\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# make prediction with best model\n",
    "y_predict = grid_search.predict(X_test)\n",
    "\n",
    "# evaluate the best model\n",
    "print('best model ', grid_search.best_params_)\n",
    "print('best score ', grid_search.best_score_)\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_predict))\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_predict))\n",
    "print('Classification Report:', classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ece91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the best model\n",
    "print('best model ', grid_search.best_params_)\n",
    "print('best score ', grid_search.best_score_)\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_predict))\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_predict))\n",
    "print('Classification Report:', classification_report(y_test, y_predict))\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e55366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classifier with the optimal hyperparameters\n",
    "log_reg = LogisticRegression(**grid_search.best_params_)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# evaluate the classifier on the test data\n",
    "print('accuracy score :', accuracy_score(y_test, y_pred))\n",
    "print('classification: ', classification_report(y_test, y_pred))\n",
    "print('confusion matrix: ', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create an object of the class and train the model\n",
    "decision_tree = Pipeline([('tfidf', TfidfVectorizer()), ('DT_classifier', DecisionTreeClassifier(random_state=42))])\n",
    "decision_tree.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Evaluate the performance of the model using classification, confussion matrix and accuracy score\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "\n",
    "# create an object of the class and train the model\n",
    "svm_clf = Pipeline([('tfidf', TfidfVectorizer()), ('svm_classifier', SVC(kernel='linear', C=1, random_state=42))])\n",
    "svm_clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Evaluate the performance of the model using classification, confussion matrix and accuracy score\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy Score:\\n', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d67c6",
   "metadata": {},
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eaae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Actual labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificatio report visualization\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "sns.heatmap(pd.DataFrame(class_report).iloc[:-1, :-1], annot=True, cmap='Blues')\n",
    "# plt.figure(figsize=(50, 170))\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Actual labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9798dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc auc visualization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_test_num = le.fit_transform(y_test)\n",
    "y_pred_num = le.transform(y_pred)\n",
    "\n",
    "auc = roc_auc_score(y_test_num, y_pred_num)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_num, y_pred_num)\n",
    "plt.plot(fpr, tpr, label='AUC')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c816964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision recall visualization\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_num, y_pred_num)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35938e7c",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923874c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the model\n",
    "dump(log_reg, 'logistic_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69135806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unseen data \n",
    "unseen_data = [\n",
    "    \"thought movie right good job nt creative origi.\",\n",
    "    \"This movie is hate; I like it!\",\n",
    "]\n",
    "# Xs = vectorizer.transform(unseen_data)\n",
    "y_pred = log_reg.predict(unseen_data)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "load_model = load('logistic_reg.pkl')\n",
    "load_model.predict(unseen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e0ed4",
   "metadata": {},
   "source": [
    "## Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "data['review'] = data['review'].str.lower()\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data['review'])\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d37f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddaa161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71707b94",
   "metadata": {},
   "source": [
    "\"\"\" to solve this problem 'AttributeError                            Traceback (most recent call last)\n",
    "C:\\Users\\HOLART~1\\AppData\\Local\\Temp/ipykernel_9900/1904468047.py in <module>\n",
    "----> 1 nb_classifier.predict(['Wow, this is amazing lesson'].reshape(-1, 1))\n",
    "AttributeError: list object has no attribute reshape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ce1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9777cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f87445",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1adb7",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn .metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create an object of the class\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# evaluate model performance\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73dba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create an object of the class\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea668af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create an object of the class\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7decbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create an SVM classifier object\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_clf.predict(X_test)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:', classification_report(y_test, y_pred))\n",
    "print('Confussion Matrix:', confusion_matrix(y_test, y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09072a",
   "metadata": {},
   "source": [
    "exploring other SVM kernels to see which one works best for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132acc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of kernels\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# loop through each kernel and train an SVM model\n",
    "for kernel in kernels:\n",
    "    # create an object of svm\n",
    "    svm_clf = SVC(kernel=kernel, C=1, random_state=42)\n",
    "    \n",
    "    # train model on the data\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction on the testing data\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    \n",
    "    # evaluate the model's peformance\n",
    "    print('Kernel: ', kernel)\n",
    "    print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "    print('classification report:', classification_report(y_test, y_pred))\n",
    "    print('confussion matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a85b5",
   "metadata": {},
   "source": [
    "tune other hyperparameters like C and degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of kernels\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# define a dictionary of hyperparameters to try for each kernel\n",
    "param_grid = {\n",
    "    'linear': {'C':[0.1,1,10]},\n",
    "    'poly': {'C':[0.1, 1, 10], \n",
    "             'degree':[2, 3, 4]},\n",
    "    'rbf':{'C':[0.1, 1, 10],\n",
    "          'gamma':['scale', 'auto']},\n",
    "    'sigmoid':{'C':[0.1, 1, 10]}\n",
    "             }\n",
    "\n",
    "# loop through each kernel and train an SVM model\n",
    "for kernel in kernels:\n",
    "    # create an object of svm\n",
    "    svm_clf = SVC(kernel=kernel, C=1, random_state=42)\n",
    "    \n",
    "    # perform grid search over the hyperparameters for the current kernel\n",
    "    grid_search = GridSearchCV(svm_clf, param_grid[kernel], cv=5, scoring='f1_macro')\n",
    "    \n",
    "    \n",
    "    # train model on the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction on the testing data\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # evaluate the model's peformance\n",
    "    print('Kernel: ', kernel)\n",
    "    print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "    print('classification: ', classification_report(y_test, y_pred))\n",
    "    print('confusion matrix: ', confusion_matrix(y_test, y_pred))\n",
    "    print('best params ',grid_search.best_params_)\n",
    "    print('best score ',grid_search.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an sm classifier with the optimal hyperparameters\n",
    "svm_clf = SVC(**grid_search.best_params_)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# evaluate the classifier on the test data\n",
    "print('accuracy score :', accuracy_score(y_test, y_pred))\n",
    "print('classification: ', classification_report(y_test, y_pred))\n",
    "print('confusion matrix: ', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50caece0",
   "metadata": {},
   "source": [
    "## Optimizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba54840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 3, 5, 10]}\n",
    "grid_search = GridSearchCV(nb_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce247876",
   "metadata": {},
   "source": [
    "## Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0351f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Actual labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125ec8c",
   "metadata": {},
   "source": [
    "## Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "sns.heatmap(pd.DataFrame(class_report).iloc[:-1, :-1], annot=True, cmap='Blues')\n",
    "# plt.figure(figsize=(50, 170))\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Actual labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703bd54",
   "metadata": {},
   "source": [
    "## ROC-AUC Curve Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f975d2",
   "metadata": {},
   "source": [
    "coverting the data type to numeric value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_test_num = le.fit_transform(y_test)\n",
    "y_pred_num = le.transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9664c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "auc = roc_auc_score(y_test_num, y_pred_num)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_num, y_pred_num)\n",
    "plt.plot(fpr, tpr, label='AUC')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a04d51",
   "metadata": {},
   "source": [
    "## Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_num, y_pred_num)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0e559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e6c6008",
   "metadata": {},
   "source": [
    "## Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "def calculate_feature_importance(X, y):\n",
    "    feature_importances = []\n",
    "    for feature in range(X.shape[1]):\n",
    "        feature_importances.append(np.abs(X[y==0, feature].mean()-X[y==1, feature].mean()))\n",
    "        return feature_importances\n",
    "    \n",
    "feature_importance = calculate_feature_importance(X_train, y_train)\n",
    "# feature_names = X_train.columns\n",
    "# plt.figure(figsize = (10, 6))\n",
    "# sns.barplot(x=feature_names, y=feature_importances)\n",
    "# plt.xlabel('Feature')\n",
    "# plt.ylabel('Importance')\n",
    "# plt.show()\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "import seaborn as sns\n",
    "corr_matrix = X_train.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB(**grid_search.best_params_)\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeca4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = [\n",
    "    \"thought movie right good job nt creative origi.\",\n",
    "    \"This movie is hate; I like it!\",\n",
    "]\n",
    "Xs = vectorizer.transform(unseen_data)\n",
    "y_pred = nb_classifier.predict(Xs)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804423f",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc162380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the model\n",
    "dump(nb_classifier, 'nb_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "load_model = load('nb_classifier.pkl')\n",
    "load_model.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56308336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorizer\n",
    "dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e282125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59226693",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_model = RandomForestClassifier()\n",
    "\n",
    "RFC_model.fit(X_train_cv, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
